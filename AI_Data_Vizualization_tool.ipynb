{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uFITIT9HPoQ",
        "outputId": "0abb813b-ea05-4418-f205-37b3475a21bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting speechrecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (2025.7.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading pypdf-5.8.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.7/309.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: speechrecognition, python-dotenv, pypdf\n",
            "Successfully installed pypdf-5.8.0 python-dotenv-1.1.1 speechrecognition-3.14.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai gradio pandas networkx matplotlib pypdf speechrecognition pydub python-dotenv beautifulsoup4 seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2gkdjYpHXLb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import json\n",
        "import sys\n",
        "import tempfile\n",
        "from contextlib import redirect_stdout\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from gradio.themes import Default\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPEN_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "li_rA9JFHZP7"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not API_KEY:\n",
        "    raise ValueError(\"OPENAI_API_KEY not set in environment\")\n",
        "client = OpenAI(api_key=API_KEY)\n",
        "MODEL = \"gpt-4o\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kevkpqGRHbtE"
      },
      "outputs": [],
      "source": [
        "df_state = None\n",
        "current_system_prompt = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42-bkqpjHeC7"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
        "You are DataBot, an expert data-analysis assistant.\n",
        "The dataframe columns are: {columns}.\n",
        "Use only these exact names when calling functions; never invent or guess new ones.\n",
        "\n",
        "Available functions:\n",
        " • ingest_csv(file_path) → load the CSV and refresh column list\n",
        " • execute_code(code) → run Python code with `df` as the dataframe, return stdout and any plot\n",
        "\n",
        "\n",
        "when required you can call summarize_csv function to provide summary.\n",
        "\n",
        "Whenever you need to execute any kind of code or plot, generate a Python snippet and call execute_code.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbFInh2iHgFl"
      },
      "outputs": [],
      "source": [
        "# — Tool: ingest_csv —\n",
        "def ingest_csv(file_path: str) -> dict:\n",
        "    global df_state, current_system_prompt\n",
        "    df_state = pd.read_csv(file_path)\n",
        "    cols = df_state.columns.tolist()\n",
        "    current_system_prompt = SYSTEM_PROMPT_TEMPLATE.format(columns=cols)\n",
        "    return {\n",
        "        \"rows\": df_state.shape[0],\n",
        "        \"columns\": cols,\n",
        "        \"dtypes\": df_state.dtypes.astype(str).to_dict()\n",
        "    }\n",
        "# — Tool: summarize_csv —\n",
        "def summarize_csv() -> dict:\n",
        "    if df_state is None:\n",
        "        raise ValueError(\"No dataframe loaded.\")\n",
        "    md = df_state.describe(include=\"all\").round(3).to_markdown()\n",
        "\n",
        "    return {\"markdown\": md}\n",
        "\n",
        "# — Tool: execute_code —\n",
        "def execute_code(code: str) -> dict:\n",
        "    \"\"\"\n",
        "    Execute user-provided Python code snippet in a sandboxed namespace\n",
        "    where `df` refers to df_state. Capture stdout and any Matplotlib figure.\n",
        "    \"\"\"\n",
        "    global df_state\n",
        "    if df_state is None:\n",
        "        raise ValueError(\"No DataFrame loaded. Please upload a CSV first.\")\n",
        "    # Prepare namespace\n",
        "    namespace = {\n",
        "        \"df\": df_state,\n",
        "        \"pd\": pd,\n",
        "        \"np\": np,\n",
        "        \"plt\": plt,\n",
        "        \"sns\": sns,\n",
        "    }\n",
        "    # Capture stdout\n",
        "    stdout_buffer = io.StringIO()\n",
        "    fig = None\n",
        "    try:\n",
        "        with redirect_stdout(stdout_buffer):\n",
        "            exec(code, namespace)\n",
        "        # Capture current figure if any\n",
        "        fig = plt.gcf()\n",
        "        img_bytes = None\n",
        "        if fig.axes:\n",
        "            buf = io.BytesIO()\n",
        "            fig.tight_layout()\n",
        "            fig.savefig(buf, format=\"png\")\n",
        "            plt.close(fig)\n",
        "            buf.seek(0)\n",
        "            img_bytes = buf.getvalue()\n",
        "        return {\n",
        "            \"stdout\": stdout_buffer.getvalue(),\n",
        "            \"has_image\": bool(img_bytes),\n",
        "            \"image_bytes\": img_bytes\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error executing code: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI44ifHUHjxU"
      },
      "outputs": [],
      "source": [
        "def get_function_schemas():\n",
        "    return [\n",
        "        {\n",
        "            \"name\": \"ingest_csv\",\n",
        "            \"description\": \"Load a CSV file into a DataFrame.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"file_path\": {\"type\": \"string\"}\n",
        "                },\n",
        "                \"required\": [\"file_path\"]\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"execute_code\",\n",
        "            \"description\": \"Execute Python code snippet with `df` loaded, returning stdout and plot if any.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"code\": {\"type\": \"string\"}\n",
        "                },\n",
        "                \"required\": [\"code\"]\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"summarize_csv\",\n",
        "            \"description\": \"Return descriptive statistics for numeric and categorical columns as markdown.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "        }\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6276PSKHmMu"
      },
      "outputs": [],
      "source": [
        "def chat(message, history, file):\n",
        "    global df_state, current_system_prompt\n",
        "    # Build system prompt\n",
        "    system_msg = current_system_prompt or SYSTEM_PROMPT_TEMPLATE.format(columns=\"(none yet)\")\n",
        "    msgs = [{\"role\": \"system\", \"content\": system_msg}]\n",
        "    # Replay history\n",
        "    for u, b in history:\n",
        "        msgs.append({\"role\": \"user\", \"content\": u})\n",
        "        msgs.append({\"role\": \"assistant\", \"content\": b})\n",
        "    # Decide whether to ingest CSV\n",
        "    if file is not None and df_state is None:\n",
        "        msgs.append({\"role\": \"user\", \"content\": file.name})\n",
        "        resp = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=msgs,\n",
        "            functions=get_function_schemas(),\n",
        "            function_call={\n",
        "                \"name\": \"ingest_csv\",\n",
        "                \"arguments\": json.dumps({\"file_path\": file.name})\n",
        "            }\n",
        "        )\n",
        "    else:\n",
        "        msgs.append({\"role\": \"user\", \"content\": message})\n",
        "        resp = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=msgs,\n",
        "            functions=get_function_schemas(),\n",
        "            function_call=\"auto\"\n",
        "        )\n",
        "\n",
        "    choice = resp.choices[0].message\n",
        "\n",
        "    # Plain text reply\n",
        "    if choice.content:\n",
        "        history.append((message, choice.content))\n",
        "        return history, None, \"\"\n",
        "\n",
        "    # Function call\n",
        "    fn = choice.function_call.name\n",
        "    args = json.loads(choice.function_call.arguments)\n",
        "    # Attempt tool execution\n",
        "    try:\n",
        "        if fn == \"ingest_csv\":\n",
        "            result = ingest_csv(**args)\n",
        "            tool_result = {\"message\": f\"Loaded CSV with {result['rows']} rows and {len(result['columns'])} columns.\"}\n",
        "            img = None\n",
        "        elif fn == \"execute_code\":\n",
        "            exec_res = execute_code(args[\"code\"])\n",
        "            # Prepare tool result for LLM\n",
        "            tool_result = {\"stdout\": exec_res[\"stdout\"], \"has_image\": exec_res[\"has_image\"]}\n",
        "            img = Image.open(io.BytesIO(exec_res[\"image_bytes\"])) if exec_res[\"has_image\"] else None\n",
        "        elif fn == \"summarize_csv\":\n",
        "            res = summarize_csv()\n",
        "            tool_result = {\"markdown\": res[\"markdown\"]}\n",
        "            img = None\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown function {fn}\")\n",
        "    except Exception as e:\n",
        "        # Send error back to LLM\n",
        "        error_payload = {\"error\": str(e)}\n",
        "        msgs.append({\"role\": \"function\", \"name\": fn, \"content\": json.dumps(error_payload)})\n",
        "        follow = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=msgs\n",
        "        ).choices[0].message.content\n",
        "        history.append((message, follow))\n",
        "        return history, None, \"\"\n",
        "\n",
        "    # Inject function result and get follow-up from LLM\n",
        "    msgs.append({\"role\": \"function\", \"name\": fn, \"content\": json.dumps(tool_result)})\n",
        "    follow = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=msgs\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    label = f\"[Uploaded {file.name}]\" if (fn == \"ingest_csv\") else message\n",
        "    history.append((label, follow))\n",
        "    return history, img, \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpFyTXmFHpc-",
        "outputId": "a210be60-ee71-4c42-eb1f-23f883a533e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-11-2260123879.py:4: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b4620b46a13d31fdc5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://b4620b46a13d31fdc5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with gr.Blocks(theme=Default()) as app:\n",
        "    gr.Markdown(\"## 📊 Data Analysis Chatbot\\nUpload a CSV, then ask me to summarize or plot — I’ll run code under the hood and show you the results.\")\n",
        "    file_input = gr.File(label=\"Upload CSV (.csv)\")\n",
        "    chatbot = gr.Chatbot()\n",
        "    with gr.Row():\n",
        "        user_input = gr.Textbox(placeholder=\"Type your question…\", label=None)\n",
        "        send = gr.Button(\"Send\")\n",
        "    image_out = gr.Image()\n",
        "\n",
        "    send.click(chat, inputs=[user_input, chatbot, file_input], outputs=[chatbot, image_out, user_input], queue=True)\n",
        "    user_input.submit(chat, inputs=[user_input, chatbot, file_input], outputs=[chatbot, image_out, user_input], queue=True)\n",
        "\n",
        "    app.launch(inbrowser=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGFSSVbgLtqS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}